{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.image as image\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadFaceImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    labledDataSet = np.empty((1, 10305))\n",
    "    personList = listdir(path)\n",
    "    \n",
    "    for person in personList:\n",
    "        imgList = listdir(path + \"/\" + person)\n",
    "        \n",
    "        for img in imgList:\n",
    "            anImage = image.imread(path + \"/\" + person + \"/\" + img)\n",
    "            #print(path + \"/\" + person + \"==>\" + img)\n",
    "            anImage = anImage.flatten()\n",
    "            labledSample = np.concatenate(([\"face\"], anImage))\n",
    "            labledSample = labledSample.reshape(1, 10305)\n",
    "            labledDataSet = np.append(labledDataSet, labledSample, 0)\n",
    "    \n",
    "    labledDataSet = labledDataSet[1:,:]\n",
    "    return labledDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadNonFaceImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    labledDataSet = np.empty((1, 10305))\n",
    "    imgList = listdir(path)\n",
    "        \n",
    "    for img in imgList:\n",
    "        anImage = image.imread(path + \"/\" + img)\n",
    "        #print(path + \"/\" + person + \"==>\" + img)\n",
    "        anImage = anImage.flatten()\n",
    "        labledSample = np.concatenate(([\"non-face\"], anImage))\n",
    "        labledSample = labledSample.reshape(1, 10305)\n",
    "        labledDataSet = np.append(labledDataSet, labledSample, 0)\n",
    "    \n",
    "    labledDataSet = labledDataSet[1:,:]\n",
    "    return labledDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathFaces = \"att_faces/orl_faces\"\n",
    "pathNonFaces = \"rand_imgs/rand_imgs_pgm\"\n",
    "\n",
    "#load faces dataset\n",
    "labeledFaceData = loadFaceImages(pathFaces)\n",
    "\n",
    "#split the dataset\n",
    "trainingLabeledFaceData = labeledFaceData[1::2]\n",
    "testLabeledFaceData = labeledFaceData[0::2]\n",
    "\n",
    "#split the labels from the data\n",
    "trainingFaceLabels, trainingFaceData = trainingLabeledFaceData[:,0], trainingLabeledFaceData[:,1:]\n",
    "trainingFaceData = np.array(trainingFaceData).astype(np.float64)\n",
    "\n",
    "testFaceLabels, testFaceData = testLabeledFaceData[:,0], testLabeledFaceData[:,1:]\n",
    "testFaceData = np.array(testFaceData).astype(np.float64)\n",
    "\n",
    "#load non-faces dataset\n",
    "labeledNonFaceData = loadNonFaceImages(pathNonFaces)\n",
    "\n",
    "#split the dataset\n",
    "#trainingLabeledNonFaceData = labeledNonFaceData[1::2]\n",
    "#testLabeledNonFaceData = labeledNonFaceData[0::2]\n",
    "\n",
    "#split the labels from the data\n",
    "#trainingNonFaceLabels, trainingNonFaceData = trainingLabeledNonFaceData[:,0], trainingLabeledNonFaceData[:,1:]\n",
    "#trainingNonFaceData = np.array(trainingNonFaceData).astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "testNonFaceLabels, testNonFaceData = testLabeledNonFaceData[:,0], testLabeledNonFaceData[:,1:]\n",
    "testNonFaceData = np.array(testNonFaceData).astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['face' '48' '49' ... '47' '46' '46']\n",
      " ['face' '34' '34' ... '37' '40' '33']\n",
      " ['face' '60' '60' ... '32' '34' '34']\n",
      " ...\n",
      " ['face' '112' '109' ... '93' '88' '92']\n",
      " ['face' '111' '114' ... '88' '86' '92']\n",
      " ['face' '110' '112' ... '92' '87' '90']]\n",
      "======================================\n",
      "[['non-face' '215' '215' ... '95' '74' '84']\n",
      " ['non-face' '214' '214' ... '136' '110' '81']\n",
      " ['non-face' '249' '247' ... '142' '145' '144']\n",
      " ...\n",
      " ['non-face' '115' '127' ... '20' '21' '28']\n",
      " ['non-face' '90' '92' ... '125' '125' '125']\n",
      " ['non-face' '117' '121' ... '180' '174' '169']]\n"
     ]
    }
   ],
   "source": [
    "print(labeledFaceData)\n",
    "print(\"======================================\")\n",
    "print(labeledNonFaceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500L, 10305L)\n",
      "(250L, 10304L)\n",
      "(250L, 10304L)\n",
      "(250L,)\n",
      "(250L,)\n"
     ]
    }
   ],
   "source": [
    "pathFaces = \"att_faces/orl_faces\"\n",
    "pathNonFaces = \"rand_imgs/rand_imgs_pgm\"\n",
    "\n",
    "#load faces dataset\n",
    "labeledFaceData = loadFaceImages(pathFaces)\n",
    "#load non-faces dataset\n",
    "labeledNonFaceData = loadNonFaceImages(pathNonFaces)\n",
    "\n",
    "#Concatenate both datasets\n",
    "labeledData = np.row_stack((labeledFaceData,labeledNonFaceData))\n",
    "\n",
    "trainingDataset = labeledData[1::2]\n",
    "testingDataset = labeledData[0::2]\n",
    "\n",
    "x_train = trainingDataset[:, 1:]\n",
    "y_train = trainingDataset[:, 0]\n",
    "x_train = np.array(x_train).astype(np.float64)\n",
    "x_trainDict = {label: x_train[y_train == label] for label in np.unique(y_train)}\n",
    "\n",
    "\n",
    "\n",
    "x_test = testingDataset[:, 1:]\n",
    "y_test = testingDataset[:, 0]\n",
    "x_test = np.array(x_test).astype(np.float64)\n",
    "x_testDict = {test_label:x_test[y_test==test_label] for test_label in np.unique(y_test)}\n",
    "\n",
    "\n",
    "print(labeledData.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#total mean\n",
    "totalMean = np.mean(x_train, 0)\n",
    "\n",
    "classMean = dict()\n",
    "#mean of each class\n",
    "for label, data in x_trainDict.items():\n",
    "    classMean[label] = np.matrix(np.mean(data,0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sb = np.zeros((10304,10304))\n",
    "Sw = np.zeros((10304,10304))\n",
    "\n",
    "for label, class_mean in classMean.items():\n",
    "    diff = class_mean - totalMean\n",
    "    \n",
    "    Sb += x_trainDict[label].size * np.dot(diff.T, diff)\n",
    "    \n",
    "    diffWithin = x_trainDict[label] - class_mean\n",
    "    Sw += np.dot(diffWithin.T,diffWithin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get inverse of within matrix\n",
    "SwPinv = np.linalg.pinv(Sw)\n",
    "S =np.dot(SwPinv, Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get eigenVectors and eigenValues of S\n",
    "eigenValues_b, eigenVectors_b = np.linalg.eig(S)\n",
    "\n",
    "#descending order\n",
    "idx = np.argsort(eigenValues_b)[::-1]\n",
    "eigenVectors_b = eigenVectors_b[:,idx]\n",
    " # sort eigenvectors according to same index\n",
    "eigenValues_b = eigenValues_b[idx]\n",
    "\n",
    "realEigenVals_b = eigenValues_b.real\n",
    "realEigenVects_b = eigenVectors_b.real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932\n"
     ]
    }
   ],
   "source": [
    "#Classification using K-NN\n",
    "\n",
    "reduced_realEigenVects_b = realEigenVects_b[:, 0:41]\n",
    "projected_trainingSet = np.dot(x_train, reduced_realEigenVects_b)\n",
    "projected_testingSet = np.dot(x_test, reduced_realEigenVects_b)\n",
    "\n",
    "classifer_b = KNeighborsClassifier(n_neighbors= 1)\n",
    "classifer_b.fit(projected_trainingSet, y_train)\n",
    "\n",
    "prediction = classifer_b.predict(projected_testingSet)\n",
    "accuracy = accuracy_score(prediction, y_test)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
